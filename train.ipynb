{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:10:08.951633Z",
     "start_time": "2025-11-03T16:10:07.278300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.cuda\n",
    "\n",
    "from utils import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)"
   ],
   "id": "38820d315d589aff",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:10:08.956695Z",
     "start_time": "2025-11-03T16:10:08.954590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def iterate(dataset):\n",
    "    while True:\n",
    "        for batch in dataset:\n",
    "            yield batch"
   ],
   "id": "7b8f72134a4e8112",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AUC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, yPred, yTrue):\n",
    "        yPred, yTrue = yPred.detach(), yTrue.detach()\n",
    "\n",
    "        sortedPred, indices = torch.sort(yPred, dim=0, descending=True)\n",
    "        sortedLabels = yTrue.float()[indices]\n",
    "\n",
    "        tp = torch.cumsum(sortedLabels, dim=0)\n",
    "        fp = torch.cumsum(1 - sortedLabels, dim=0)\n",
    "\n",
    "        tpr = tp / (tp[-1] + 1e-8)\n",
    "        fpr = fp / (fp[-1] + 1e-8)\n",
    "\n",
    "        auc = torch.trapz(tpr, fpr)\n",
    "\n",
    "        return auc.item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T16:10:08.962130Z",
     "start_time": "2025-11-03T16:10:08.959241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def trainModel(model, loaders, config):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learningRate)\n",
    "    try:\n",
    "        objective = torch.nn.CrossEntropyLoss()\n",
    "        criterion = AUC()\n",
    "\n",
    "        testIter = iterate(loaders[\"val\"])\n",
    "\n",
    "        client = Client(\"127.0.0.1\", 12954)\n",
    "\n",
    "        for epoch in range(config.epochs):\n",
    "            progress = 0\n",
    "            for inputs, targets in loaders[\"train\"]:\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs.to(device))\n",
    "\n",
    "                loss = objective(outputs.squeeze(), targets.to(device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                trainLoss = loss.item()\n",
    "                # trainAUC = criterion(outputs.squeeze(), targets.to(device).float())\n",
    "\n",
    "                inputs1, targets1 = next(testIter)\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    outputs1 = model(inputs1.to(device))\n",
    "                    loss1 = objective(outputs1.squeeze(), targets1.to(device))\n",
    "\n",
    "                    testLoss = loss1.item()\n",
    "                    # testAUC = criterion(outputs1.squeeze(), targets1.to(device).float())\n",
    "\n",
    "                client.send(\"Train Loss\", trainLoss)\n",
    "                client.send(\"Test Loss\", testLoss)\n",
    "                # client.send(\"Train AUC\", trainAUC)\n",
    "                # client.send(\"Test AUC\", testAUC)\n",
    "\n",
    "                progress += 1\n",
    "                print(f\"\\r{epoch + 1} | {progress}/{len(loaders['train'])} | Train Loss: {trainLoss:.2f} | Test Loss: {testLoss:.2f}\", end=\"\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return model, optimizer"
   ],
   "id": "a47cc3bef58f1833",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming PCAFormer training\n",
      "KaggleHub dataset path: F:/.cache/kagglehub\\datasets\\dimensi0n\\imagenet-256\\versions\\1\n",
      "Model has 38916072 parameters\n",
      "3 | 2127/6748 | Train Loss: 7.59 | Test Loss: 6.30"
     ]
    }
   ],
   "source": [
    "resume = os.path.join(\"checkpoints\", \"PCAFormer\")\n",
    "# resume = None\n",
    "modelResolution = {\"ResNet50\": ResNet50, \"SwinTransformerV2Tiny\": SwinTransformerV2Tiny, \"PCAFormer\": PCAFormer}\n",
    "\n",
    "if resume is not None:\n",
    "    print(f\"Resuming {os.path.basename(resume)} training\")\n",
    "    modelClass = modelResolution[os.path.basename(resume)]\n",
    "    config = Config().load(os.path.join(resume, \"config.json\"))\n",
    "\n",
    "    model = modelClass(config.model)\n",
    "    model.load_state_dict(torch.load(os.path.join(resume, \"checkpoint.pt\")))\n",
    "\n",
    "else:\n",
    "    config = Config().load(os.path.join(\"configs\", \"config.json\"))\n",
    "\n",
    "    modelClass = PCAFormer\n",
    "    model = modelClass(config.model)\n",
    "\n",
    "\n",
    "if \"cacheDir\" in config:\n",
    "    os.environ[\"KAGGLEHUB_CACHE\"] = config.cacheDir\n",
    "\n",
    "dataDir = download_dataset(\"dimensi0n/imagenet-256\")\n",
    "\n",
    "config.dataset.dataDir = dataDir\n",
    "loaders = get_dataloaders(config, device)\n",
    "\n",
    "print(f\"Model has {sum([p.numel() for p in model.parameters()])} parameters\")\n",
    "\n",
    "model, optimizer = trainModel(model, loaders, config)\n",
    "\n",
    "directory = os.path.join(\"checkpoints\", modelClass.__name__)\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(directory, \"checkpoint.pt\"))\n",
    "torch.save(optimizer.state_dict(), os.path.join(directory, \"optimizer.pt\"))\n",
    "config.save(os.path.join(directory, \"config.json\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
