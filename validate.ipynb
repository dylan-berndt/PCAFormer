{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import calflops\n",
    "\n",
    "from utils import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.set_default_device(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = os.path.join(\"checkpoints\", \"PCAFormer\")\n",
    "config = Config().load(os.path.join(location, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KaggleHub dataset path: F:/.cache/kagglehub\\datasets\\dimensi0n\\imagenet-256\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "if \"cacheDir\" in config:\n",
    "    os.environ[\"KAGGLEHUB_CACHE\"] = config.cacheDir\n",
    "\n",
    "dataDir = download_dataset(\"dimensi0n/imagenet-256\")\n",
    "\n",
    "config.dataset.dataDir = dataDir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def testModel(model, testSet, criterion: dict[str, nn.Module], name):\n",
    "    model.eval()\n",
    "    metrics = {}\n",
    "    # Necessary for weighted mean\n",
    "    weights = []\n",
    "    flops, macs, params = None, None, None\n",
    "    with torch.no_grad():\n",
    "        progress = 0\n",
    "        for inputs, targets in testSet:\n",
    "            if flops is None:\n",
    "                flops, macs, params = calflops.calculate_flops(model, input_shape=tuple(inputs.shape))\n",
    "\n",
    "            outputs = model(inputs.to(device))\n",
    "            for metric in criterion:\n",
    "                if metric not in metrics:\n",
    "                    metrics[metric] = []\n",
    "                metrics[metric].append(criterion[metric](outputs, targets.to(device)).item())\n",
    "            weights.append(inputs.shape[0])\n",
    "\n",
    "            progress += 1\n",
    "            print(f\"\\r{name} | {progress}/{len(testSet)} | Accuracy: {metrics['Accuracy'][-1]:.2f} | Perplexity: {metrics['Perplexity'][-1]:.2f}\", end=\"\")\n",
    "\n",
    "    weights = np.array(weights)\n",
    "    for metric in metrics:\n",
    "        metrics[metric] = np.sum(np.array(metrics[metric]) * weights) / np.sum(weights)\n",
    "\n",
    "    metrics[\"FLOPS\"] = flops\n",
    "    metrics[\"MACS\"] = macs\n",
    "    metrics[\"Params\"] = params\n",
    "\n",
    "    return metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Accuracy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, yPred, yTrue):\n",
    "        indices = torch.argmax(yPred, dim=1)\n",
    "        return torch.mean((indices == yTrue).float())\n",
    "\n",
    "\n",
    "class Perplexity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, yPred, yTrue):\n",
    "        log = self.entropy(yPred, yTrue)\n",
    "        return torch.exp(log)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------- Calculate Flops Results -------------------------------------\n",
      "Notations:\n",
      "number of parameters (Params), number of multiply-accumulate operations(MACs),\n",
      "number of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\n",
      "fwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\n",
      "default model backpropagation takes 2.00 times as much computation as forward propagation.\n",
      "\n",
      "Total Training Params:                                                  25.56 M \n",
      "fwd MACs:                                                               261.71 GMACs\n",
      "fwd FLOPs:                                                              527.61 GFLOPS\n",
      "fwd+bwd MACs:                                                           785.12 GMACs\n",
      "fwd+bwd FLOPs:                                                          1.58 TFLOPS\n",
      "\n",
      "-------------------------------- Detailed Calculated FLOPs Results --------------------------------\n",
      "Each module caculated is listed after its name in the following order: \n",
      "params, percentage of total params, MACs, percentage of total MACs, FLOPS, percentage of total FLOPs\n",
      "\n",
      "Note: 1. A module can have torch.nn.module or torch.nn.functional to compute logits (e.g. CrossEntropyLoss). \n",
      " They are not counted as submodules in calflops and not to be printed out. However they make up the difference between a parent's MACs and the sum of its submodules'.\n",
      "2. Number of floating-point operations is a theoretical estimation, thus FLOPS computed using that could be larger than the maximum system throughput.\n",
      "\n",
      "ResNet(\n",
      "  25.56 M = 100% Params, 261.71 GMACs = 100% MACs, 527.61 GFLOPS = 100% FLOPs\n",
      "  (conv1): Conv2d(9.41 K = 0.04% Params, 7.55 GMACs = 2.89% MACs, 15.11 GFLOPS = 2.86% FLOPs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 205.52 MFLOPS = 0.04% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, inplace=True)\n",
      "  (maxpool): MaxPool2d(0 = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    215.81 K = 0.84% Params, 42.75 GMACs = 16.33% MACs, 87.09 GFLOPS = 16.51% FLOPs\n",
      "    (0): Bottleneck(\n",
      "      75.01 K = 0.29% Params, 14.8 GMACs = 5.65% MACs, 30.26 GFLOPS = 5.74% FLOPs\n",
      "      (conv1): Conv2d(4.1 K = 0.02% Params, 822.08 MMACs = 0.31% MACs, 1.64 GFLOPS = 0.31% FLOPs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 K = 0.14% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 205.52 MFLOPS = 0.04% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 154.14 MFLOPS = 0.03% FLOPs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        16.9 K = 0.07% Params, 3.29 GMACs = 1.26% MACs, 6.78 GFLOPS = 1.29% FLOPs\n",
      "        (0): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 205.52 MFLOPS = 0.04% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      70.4 K = 0.28% Params, 13.98 GMACs = 5.34% MACs, 28.41 GFLOPS = 5.39% FLOPs\n",
      "      (conv1): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 K = 0.14% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 205.52 MFLOPS = 0.04% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 154.14 MFLOPS = 0.03% FLOPs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      70.4 K = 0.28% Params, 13.98 GMACs = 5.34% MACs, 28.41 GFLOPS = 5.39% FLOPs\n",
      "      (conv1): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(36.86 K = 0.14% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16.38 K = 0.06% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 205.52 MFLOPS = 0.04% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 154.14 MFLOPS = 0.03% FLOPs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    1.22 M = 4.77% Params, 65.77 GMACs = 25.13% MACs, 132.68 GFLOPS = 25.15% FLOPs\n",
      "    (0): Bottleneck(\n",
      "      379.39 K = 1.48% Params, 23.84 GMACs = 9.11% MACs, 48.13 GFLOPS = 9.12% FLOPs\n",
      "      (conv1): Conv2d(32.77 K = 0.13% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 K = 0.58% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 115.61 MFLOPS = 0.02% FLOPs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        132.1 K = 0.52% Params, 6.58 GMACs = 2.51% MACs, 13.26 GFLOPS = 2.51% FLOPs\n",
      "        (0): Conv2d(131.07 K = 0.51% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      280.06 K = 1.1% Params, 13.98 GMACs = 5.34% MACs, 28.18 GFLOPS = 5.34% FLOPs\n",
      "      (conv1): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 K = 0.58% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 77.07 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      280.06 K = 1.1% Params, 13.98 GMACs = 5.34% MACs, 28.18 GFLOPS = 5.34% FLOPs\n",
      "      (conv1): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 K = 0.58% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 77.07 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      280.06 K = 1.1% Params, 13.98 GMACs = 5.34% MACs, 28.18 GFLOPS = 5.34% FLOPs\n",
      "      (conv1): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(147.46 K = 0.58% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256 = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(65.54 K = 0.26% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 102.76 MFLOPS = 0.02% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 77.07 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    7.1 M = 27.77% Params, 93.72 GMACs = 35.81% MACs, 188.24 GFLOPS = 35.68% FLOPs\n",
      "    (0): Bottleneck(\n",
      "      1.51 M = 5.92% Params, 23.84 GMACs = 9.11% MACs, 47.91 GFLOPS = 9.08% FLOPs\n",
      "      (conv1): Conv2d(131.07 K = 0.51% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 57.8 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        526.34 K = 2.06% Params, 6.58 GMACs = 2.51% MACs, 13.2 GFLOPS = 2.5% FLOPs\n",
      "        (0): Conv2d(524.29 K = 2.05% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      1.12 M = 4.37% Params, 13.98 GMACs = 5.34% MACs, 28.07 GFLOPS = 5.32% FLOPs\n",
      "      (conv1): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 38.54 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      1.12 M = 4.37% Params, 13.98 GMACs = 5.34% MACs, 28.07 GFLOPS = 5.32% FLOPs\n",
      "      (conv1): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 38.54 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      1.12 M = 4.37% Params, 13.98 GMACs = 5.34% MACs, 28.07 GFLOPS = 5.32% FLOPs\n",
      "      (conv1): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 38.54 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      1.12 M = 4.37% Params, 13.98 GMACs = 5.34% MACs, 28.07 GFLOPS = 5.32% FLOPs\n",
      "      (conv1): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 38.54 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      1.12 M = 4.37% Params, 13.98 GMACs = 5.34% MACs, 28.07 GFLOPS = 5.32% FLOPs\n",
      "      (conv1): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(589.82 K = 2.31% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(262.14 K = 1.03% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2.05 K = 0.01% Params, 0 MACs = 0% MACs, 51.38 MFLOPS = 0.01% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 38.54 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    14.96 M = 58.55% Params, 51.79 GMACs = 19.79% MACs, 103.81 GFLOPS = 19.68% FLOPs\n",
      "    (0): Bottleneck(\n",
      "      6.04 M = 23.63% Params, 23.84 GMACs = 9.11% MACs, 47.79 GFLOPS = 9.06% FLOPs\n",
      "      (conv1): Conv2d(524.29 K = 2.05% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M = 9.23% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M = 4.1% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 K = 0.02% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 28.9 MFLOPS = 0.01% FLOPs, inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        2.1 M = 8.22% Params, 6.58 GMACs = 2.51% MACs, 13.18 GFLOPS = 2.5% FLOPs\n",
      "        (0): Conv2d(2.1 M = 8.21% Params, 6.58 GMACs = 2.51% MACs, 13.15 GFLOPS = 2.49% FLOPs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(4.1 K = 0.02% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      4.46 M = 17.46% Params, 13.98 GMACs = 5.34% MACs, 28.01 GFLOPS = 5.31% FLOPs\n",
      "      (conv1): Conv2d(1.05 M = 4.1% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M = 9.23% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M = 4.1% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 K = 0.02% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 19.27 MFLOPS = 0% FLOPs, inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      4.46 M = 17.46% Params, 13.98 GMACs = 5.34% MACs, 28.01 GFLOPS = 5.31% FLOPs\n",
      "      (conv1): Conv2d(1.05 M = 4.1% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2.36 M = 9.23% Params, 7.4 GMACs = 2.83% MACs, 14.8 GFLOPS = 2.8% FLOPs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1.02 K = 0% Params, 0 MACs = 0% MACs, 6.42 MFLOPS = 0% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1.05 M = 4.1% Params, 3.29 GMACs = 1.26% MACs, 6.58 GFLOPS = 1.25% FLOPs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(4.1 K = 0.02% Params, 0 MACs = 0% MACs, 25.69 MFLOPS = 0% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0 = 0% Params, 0 MACs = 0% MACs, 19.27 MFLOPS = 0% FLOPs, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(0 = 0% Params, 0 MACs = 0% MACs, 12.85 MFLOPS = 0% FLOPs, output_size=(1, 1))\n",
      "  (fc): Linear(2.05 M = 8.02% Params, 131.07 MMACs = 0.05% MACs, 262.14 MFLOPS = 0.05% FLOPs, in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "---------------------------------------------------------------------------------------------------\n",
      "ResNet50 | 583/1687 | Accuracy: 0.88 | Perplexity: 1.50"
     ]
    }
   ],
   "source": [
    "def loadPCA(x):\n",
    "    pcaFormer = PCAFormer(config.model)\n",
    "    pcaFormer.load_state_dict(torch.load(os.path.join(location, \"checkpoint.pt\")))\n",
    "    return pcaFormer\n",
    "\n",
    "loadResNet = lambda x: resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "loadSwin = lambda x: swin_v2_t(weights=Swin_V2_T_Weights.IMAGENET1K_V1)\n",
    "loadVIT = lambda x: vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "modelLoaders = [loadResNet, loadSwin, loadVIT, loadPCA]\n",
    "transforms = [ResNet50_Weights.IMAGENET1K_V1.transforms(), Swin_V2_T_Weights.IMAGENET1K_V1.transforms(),\n",
    "              ViT_B_16_Weights.IMAGENET1K_V1.transforms(), None]\n",
    "modelNames = [\"ResNet50\", \"SwinTransformer-Tiny\", \"ViT-Base-16\", \"PCAFormer\"]\n",
    "collectedMetrics = []\n",
    "\n",
    "criterion = {\"Accuracy\": Accuracy(), \"Perplexity\": Perplexity()}\n",
    "\n",
    "for m, modelLoader in enumerate(modelLoaders):\n",
    "    loaders = get_dataloaders(config, device, transforms[m])\n",
    "    currentModel = modelLoader(None)\n",
    "    modelMetrics = testModel(currentModel, loaders[\"val\"], criterion, modelNames[m])\n",
    "    collectedMetrics.append(modelMetrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flops = [collectedMetric[\"FLOPS\"] for collectedMetric in collectedMetrics]\n",
    "for metric in criterion:\n",
    "    measure = [collectedMetric[metric] for collectedMetric in collectedMetrics]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(flops, measure)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xlabel(\"FLOPS\")\n",
    "\n",
    "    for i, name in enumerate(modelNames):\n",
    "        ax.annotate(name, (flops[i], measure[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
